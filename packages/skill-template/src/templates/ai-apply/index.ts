import { Document } from '@langchain/core/documents';
import { BaseMessage, HumanMessage, SystemMessage } from '@langchain/core/messages';

import { START, END, StateGraphArgs, StateGraph } from '@langchain/langgraph';
import { BaseSkill, BaseSkillState, SkillRunnableConfig, baseStateGraphArgs } from '../../base';
// schema
import { z } from 'zod';
import { Icon, SkillInvocationConfig, SkillTemplateConfigSchema } from '@refly/openapi-schema';

interface GraphState extends BaseSkillState {
  documents: Document[];
  messages: BaseMessage[];
}

// Define a new graph
export class AIApplySkill extends BaseSkill {
  name = 'ai_apply';
  displayName = {
    en: 'AI Apply',
    'zh-CN': 'AI åº”ç”¨',
  };

  icon: Icon = { type: 'emoji', value: 'ðŸ“„' };

  configSchema: SkillTemplateConfigSchema = {
    items: [],
  };

  invocationConfig: SkillInvocationConfig = {
    input: {
      rules: [{ key: 'query' }],
    },
    context: {
      rules: [
        {
          key: 'contentList',
          inputMode: 'multiSelect',
          defaultValue: ['noteCursorSelection', 'noteBeforeCursorSelection', 'noteAfterCursorSelection'],
        },
      ],
    },
  };

  description = 'Create the article outline';

  schema = z.object({
    query: z.string().describe('The user query'),
  });

  graphState: StateGraphArgs<GraphState>['channels'] = {
    ...baseStateGraphArgs,
    documents: {
      reducer: (left?: Document[], right?: Document[]) => (right ? right : left || []),
      default: () => [],
    },
    messages: {
      reducer: (x: BaseMessage[], y: BaseMessage[]) => x.concat(y),
      default: () => [],
    },
  };

  async generate(state: GraphState, config?: SkillRunnableConfig) {
    this.engine.logger.log('---GENERATE---');

    const { query } = state;
    const { locale = 'en', contentList = [], resources = [], chatHistory = [] } = config?.configurable || {};

    const llm = this.engine.chatModel({
      temperature: 0.2,
    });

    const systemPrompt = `- è§’è‰²ï¼šå†…å®¹ä¼˜åŒ–ä¸“å®¶
- èƒŒæ™¯ï¼šç”¨æˆ·æä¾›äº†ä¸€æ®µå†…å®¹å’Œä¼˜åŒ–å»ºè®®ï¼Œéœ€è¦æ‚¨åŸºäºŽè¿™äº›ä¿¡æ¯è¿›è¡Œå†…å®¹ä¼˜åŒ–ã€‚
- æŠ€èƒ½ï¼šæ‚¨æ“…é•¿åˆ†æžçŽ°æœ‰å†…å®¹ï¼Œç†è§£ä¼˜åŒ–å»ºè®®ï¼Œå¹¶ç»“åˆä¸¤è€…ç»™å‡ºæ”¹è¿›åŽçš„å®Œæ•´å†…å®¹ã€‚
- ç›®æ ‡ï¼šæä¾›ä¸€ä¸ªç»è¿‡ä¼˜åŒ–çš„ã€å®Œæ•´çš„å†…å®¹ç‰ˆæœ¬ï¼Œæ—¢ä¿ç•™åŽŸå†…å®¹çš„æ ¸å¿ƒä¿¡æ¯ï¼Œåˆèžå…¥ä¼˜åŒ–å»ºè®®ã€‚
- çº¦æŸï¼šä¿æŒå†…å®¹çš„è¿žè´¯æ€§å’Œé€»è¾‘æ€§ï¼Œç¡®ä¿ä¼˜åŒ–åŽçš„å†…å®¹æ›´åŠ æ¸…æ™°ã€å‡†ç¡®å’Œæœ‰æ•ˆã€‚
- è¾“å‡ºæ ¼å¼ï¼šè¯·æä¾›å®Œæ•´çš„ä¼˜åŒ–åŽå†…å®¹ï¼Œä¿æŒåŽŸæœ‰çš„è¯­è¨€å’Œæ ¼å¼ã€‚

# åŽŸå§‹å†…å®¹
---
{context}
---

# ä¼˜åŒ–å»ºè®®
{query}

# å·¥ä½œæµç¨‹
1. ä»”ç»†é˜…è¯»åŽŸå§‹å†…å®¹ï¼Œç†è§£å…¶ä¸»è¦è§‚ç‚¹å’Œç»“æž„ã€‚
2. åˆ†æžç”¨æˆ·æä¾›çš„ä¼˜åŒ–å»ºè®®ï¼Œæ˜Žç¡®éœ€è¦æ”¹è¿›çš„æ–¹é¢ã€‚
3. ç»“åˆåŽŸå†…å®¹å’Œä¼˜åŒ–å»ºè®®ï¼Œè¿›è¡Œä»¥ä¸‹ä¼˜åŒ–ï¼š
   - æ”¹è¿›å†…å®¹çš„ç»“æž„å’Œç»„ç»‡
   - å¢žå¼ºè¡¨è¾¾çš„æ¸…æ™°åº¦å’Œå‡†ç¡®æ€§
   - è¡¥å……æˆ–åˆ å‡ç›¸å…³ä¿¡æ¯
   - è°ƒæ•´è¯­è¨€é£Žæ ¼ï¼ˆå¦‚éœ€è¦ï¼‰
4. ç¡®ä¿ä¼˜åŒ–åŽçš„å†…å®¹ä¿æŒåŽŸæœ‰çš„æ ¸å¿ƒä¿¡æ¯å’Œä¸»é¢˜ã€‚
5. æä¾›å®Œæ•´çš„ä¼˜åŒ–åŽå†…å®¹ã€‚

## é‡è¦æç¤º
è¯·åˆ†æžæä¾›çš„å†…å®¹è¯­è¨€ï¼Œç¡®ä¿æ‚¨çš„å›žå¤ä½¿ç”¨ç›¸åŒçš„è¯­è¨€ã€‚å¦‚æžœå†…å®¹æ˜¯ä¸­æ–‡ï¼Œè¯·ç”¨ä¸­æ–‡å›žå¤ï¼›å¦‚æžœæ˜¯è‹±æ–‡ï¼Œè¯·ç”¨è‹±æ–‡å›žå¤ã€‚å¯¹äºŽå…¶ä»–è¯­è¨€ï¼Œè¯·ä½¿ç”¨ç›¸åº”çš„è¯­è¨€å›žå¤ã€‚

è¯·ç›´æŽ¥è¾“å‡ºä¼˜åŒ–åŽçš„å®Œæ•´å†…å®¹ï¼Œæ— éœ€é¢å¤–è§£é‡Šã€‚
`;

    let contextString = '';
    if (resources.length > 0) {
      contextString = resources
        .map(
          (item) => `
    ---${item?.resource?.title}---
    ${item?.resource?.content}
    ---
    `,
        )
        .join('\n\n');
    } else if (contentList.length > 0) {
      contextString = contentList.map((item) => item?.content).join('\n\n');
    } else {
      contextString = 'No additional context provided.';
    }

    const prompt = systemPrompt.replace('{context}', contextString).replace('{query}', query);

    const responseMessage = await llm.invoke([
      new SystemMessage(prompt),
      new HumanMessage(`The context is provided above, please apply the ai with give content and modify suggestions`),
    ]);

    return { messages: [responseMessage] };
  }

  toRunnable() {
    const workflow = new StateGraph<GraphState>({
      channels: this.graphState,
    })
      .addNode('generate', this.generate.bind(this))
      .addEdge(START, 'generate')
      .addEdge('generate', END);

    return workflow.compile();
  }
}
